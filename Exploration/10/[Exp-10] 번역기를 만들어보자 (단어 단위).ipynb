{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e59f9fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import os, re, string\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb5b933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78004</th>\n",
       "      <td>He finally met my demands.</td>\n",
       "      <td>Il a finalement satisfait à mes exigences.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170953</th>\n",
       "      <td>I don't know whether to believe him or not.</td>\n",
       "      <td>Je ne sais pas si je dois le croire ou non.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126807</th>\n",
       "      <td>Tom is someone I really respect.</td>\n",
       "      <td>Tom est quelqu'un que je respecte vraiment.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172133</th>\n",
       "      <td>There are people who are afraid of spiders.</td>\n",
       "      <td>Il y a des personnes qui ont peur des araignées.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101994</th>\n",
       "      <td>I am not good at mathematics.</td>\n",
       "      <td>Je ne suis pas bon en mathématiques.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                eng  \\\n",
       "78004                    He finally met my demands.   \n",
       "170953  I don't know whether to believe him or not.   \n",
       "126807             Tom is someone I really respect.   \n",
       "172133  There are people who are afraid of spiders.   \n",
       "101994                I am not good at mathematics.   \n",
       "\n",
       "                                                     fra  \\\n",
       "78004         Il a finalement satisfait à mes exigences.   \n",
       "170953       Je ne sais pas si je dois le croire ou non.   \n",
       "126807       Tom est quelqu'un que je respecte vraiment.   \n",
       "172133  Il y a des personnes qui ont peur des araignées.   \n",
       "101994              Je ne suis pas bon en mathématiques.   \n",
       "\n",
       "                                                       cc  \n",
       "78004   CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "170953  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "126807  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "172133  CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "101994  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2763c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>Be watchful.</td>\n",
       "      <td>Fais attention.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12242</th>\n",
       "      <td>Tom likes them.</td>\n",
       "      <td>Tom les apprécie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21404</th>\n",
       "      <td>Try not to laugh.</td>\n",
       "      <td>Essaie de ne pas rigoler.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24294</th>\n",
       "      <td>I owe you a favor.</td>\n",
       "      <td>Je vous dois une faveur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13835</th>\n",
       "      <td>Horses run fast.</td>\n",
       "      <td>Un cheval court vite.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                        fra\n",
       "2818         Be watchful.            Fais attention.\n",
       "12242     Tom likes them.          Tom les apprécie.\n",
       "21404   Try not to laugh.  Essaie de ne pas rigoler.\n",
       "24294  I owe you a favor.   Je vous dois une faveur.\n",
       "13835    Horses run fast.      Un cheval court vite."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 5만개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d4d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24398</th>\n",
       "      <td>I should head out.</td>\n",
       "      <td>\\t Je devrais sortir. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>We're worried.</td>\n",
       "      <td>\\t Nous nous faisons du souci. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21032</th>\n",
       "      <td>Tom is Mary's ex.</td>\n",
       "      <td>\\t Tom est l'ex de Mary. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>I'm right.</td>\n",
       "      <td>\\t J'ai raison. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18293</th>\n",
       "      <td>Here is your dog.</td>\n",
       "      <td>\\t Voici ton chien. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                                fra\n",
       "24398  I should head out.           \\t Je devrais sortir. \\n\n",
       "9285       We're worried.  \\t Nous nous faisons du souci. \\n\n",
       "21032   Tom is Mary's ex.        \\t Tom est l'ex de Mary. \\n\n",
       "1210           I'm right.                 \\t J'ai raison. \\n\n",
       "18293   Here is your dog.             \\t Voici ton chien. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27900729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Va ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Marche. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t En route ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Bouge ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut ! \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eng               fra\n",
       "0  Go.        \\t Va ! \\n\n",
       "1  Go.     \\t Marche. \\n\n",
       "2  Go.  \\t En route ! \\n\n",
       "3  Go.     \\t Bouge ! \\n\n",
       "4  Hi.     \\t Salut ! \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81aca864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_punctuation(s): return re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16d53791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go . ', 'Go . ', 'Go . ', 'Go . ', 'Hi . ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex reference: https://stackoverflow.com/questions/64125019/how-to-tokenize-punctuations-using-the-tokenizer-function-tensorflow\n",
    "# create a full list from lines.eng and separate by punctuation\n",
    "list_eng = [pad_punctuation(s) for s in lines.eng]\n",
    "list_eng[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3466436e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t Va  !  \\n',\n",
       " '\\t Marche .  \\n',\n",
       " '\\t En route  !  \\n',\n",
       " '\\t Bouge  !  \\n',\n",
       " '\\t Salut  !  \\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fra = [pad_punctuation(s) for s in lines.fra]\n",
    "list_fra[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b11438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 1], [29, 1], [29, 1]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(filters='')    # 문자 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(list_eng)               # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(list_eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b98d36e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tom', '?', '.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer.index_word[6], eng_tokenizer.index_word[5], eng_tokenizer.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aff9db9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 76, 10, 2], [1, 345, 3, 2], [1, 27, 486, 10, 2]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(filters='')   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(list_fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(list_fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c09bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\t', '\\n', '.', \"'\", 'je', 'est')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer.index_word[1], fra_tokenizer.index_word[2],fra_tokenizer.index_word[3], fra_tokenizer.index_word[4], fra_tokenizer.index_word[5], fra_tokenizer.index_word[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "250f0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 9467\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63339225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae7861c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 9467\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93369a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26842291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 76, 10], [1, 345, 3], [1, 27, 486, 10]]\n",
      "[[76, 10, 2], [345, 3, 2], [27, 486, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb501c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4384094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29  1  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b8d6d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10, 4713)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20, 9467)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20, 9467)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320a78f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 10, 4713)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 20, 9467)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 20, 9467)\n",
      "enc_inp_tr (30000, 10, 4713)\n",
      "dec_inp_tr (30000, 20, 9467)\n",
      "dec_tgt_tr (30000, 20, 9467)\n",
      "enc_inp_ts (3000, 10, 4713)\n",
      "dec_inp_ts (3000, 20, 9467)\n",
      "dec_tgt_ts (3000, 20, 9467)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))\n",
    "print('enc_inp_tr', np.shape(encoder_input_train))\n",
    "print('dec_inp_tr', np.shape(decoder_input_train))\n",
    "print('dec_tgt_tr', np.shape(decoder_target_train))\n",
    "print('enc_inp_ts', np.shape(encoder_input_test))\n",
    "print('dec_inp_ts', np.shape(decoder_input_test))\n",
    "print('dec_tgt_ts', np.shape(decoder_target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f7c2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(eng_vocab_size, 100, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "encoder_lstm = LSTM(100, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81ccc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(fra_vocab_size, 100, input_length=max_fra_seq_len)(decoder_inputs)\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(100, return_sequences = True, return_state=True)\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(dec_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5f91319",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "291f2536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    471300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    946700      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 100), (None, 80400       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 100),  80400       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9467)   956167      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,534,967\n",
      "Trainable params: 2,534,967\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba98911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a5849",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "1회차\n",
    "- TypeError: Inputs to a layer should be tensors. Got: <keras.layers.embeddings.Embedding object at 0x7f05a2a51d30> 문제가 계속 생겼었다.\n",
    "    - 타입 에러가 뭔지는 알지만, 고치는 방법을 찾지 못했었다.\n",
    "    - https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html 여기를 가서 모델 빌딩을 따라해 보자는 마음가짐으로 한번 훑어보다가 고치는 방법을 알아내었다. Shape을 정해주고 난 후에 (encoder_inputs)을 옆에 붙여줌으로써 해결하였다.\n",
    "- TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType' 라는 문제가 decoding model을 만드는 과정에서 에러가 생겼다.\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c37a9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
