{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e69b1faf",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36902515",
   "metadata": {},
   "source": [
    "### Load libraries, load file, and add sos/eos tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f57070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import os, re, string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbcfdfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134232</th>\n",
       "      <td>Could you tell me what time it is?</td>\n",
       "      <td>Pourrais-tu me donner l'heure ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94654</th>\n",
       "      <td>I couldn't sleep last night.</td>\n",
       "      <td>Je n'ai pu dormir la nuit dernière.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133052</th>\n",
       "      <td>We don't have a landline anymore.</td>\n",
       "      <td>Nous n'avons plus de ligne fixe.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107686</th>\n",
       "      <td>You should get your hair cut.</td>\n",
       "      <td>Tu devrais te couper les cheveux.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133454</th>\n",
       "      <td>Who knows what's going to happen?</td>\n",
       "      <td>Qui sait ce qui va avoir lieu ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       eng  \\\n",
       "134232  Could you tell me what time it is?   \n",
       "94654         I couldn't sleep last night.   \n",
       "133052   We don't have a landline anymore.   \n",
       "107686       You should get your hair cut.   \n",
       "133454   Who knows what's going to happen?   \n",
       "\n",
       "                                        fra  \\\n",
       "134232      Pourrais-tu me donner l'heure ?   \n",
       "94654   Je n'ai pu dormir la nuit dernière.   \n",
       "133052     Nous n'avons plus de ligne fixe.   \n",
       "107686    Tu devrais te couper les cheveux.   \n",
       "133454      Qui sait ce qui va avoir lieu ?   \n",
       "\n",
       "                                                       cc  \n",
       "134232  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "94654   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "133052  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "107686  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "133454  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) # print 5 random samples/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b65d5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13638</th>\n",
       "      <td>Guys are stupid.</td>\n",
       "      <td>Les mecs sont stupides.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23375</th>\n",
       "      <td>He lives frugally.</td>\n",
       "      <td>Il vit de manière frugale.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7456</th>\n",
       "      <td>I made a list.</td>\n",
       "      <td>Je fis une liste.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24022</th>\n",
       "      <td>I hope this works.</td>\n",
       "      <td>J'espère que ça fonctionne.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>Try it on.</td>\n",
       "      <td>Essaie-le !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                          fra\n",
       "13638    Guys are stupid.      Les mecs sont stupides.\n",
       "23375  He lives frugally.   Il vit de manière frugale.\n",
       "7456       I made a list.            Je fis une liste.\n",
       "24022  I hope this works.  J'espère que ça fonctionne.\n",
       "1566           Try it on.                  Essaie-le !"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 33000 rows to be used\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60bf12a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24294</th>\n",
       "      <td>I owe you a favor.</td>\n",
       "      <td>\\t Je vous dois une faveur. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9558</th>\n",
       "      <td>You're sleepy.</td>\n",
       "      <td>\\t Tu es endormie. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22865</th>\n",
       "      <td>Did you know that?</td>\n",
       "      <td>\\t Le savais-tu ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18428</th>\n",
       "      <td>I am out of work.</td>\n",
       "      <td>\\t Je suis sans travail. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21652</th>\n",
       "      <td>We're dozing off.</td>\n",
       "      <td>\\t Nous nous assoupissons. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                             fra\n",
       "24294  I owe you a favor.  \\t Je vous dois une faveur. \\n\n",
       "9558       You're sleepy.           \\t Tu es endormie. \\n\n",
       "22865  Did you know that?            \\t Le savais-tu ? \\n\n",
       "18428   I am out of work.     \\t Je suis sans travail. \\n\n",
       "21652   We're dozing off.   \\t Nous nous assoupissons. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add sos and eos tokens\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474eadd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Va ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Marche. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t En route ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Bouge ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Cours ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Courez ! \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng               fra\n",
       "0   Go.        \\t Va ! \\n\n",
       "1   Go.     \\t Marche. \\n\n",
       "2   Go.  \\t En route ! \\n\n",
       "3   Go.     \\t Bouge ! \\n\n",
       "4   Hi.     \\t Salut ! \\n\n",
       "5   Hi.      \\t Salut. \\n\n",
       "6  Run!     \\t Cours ! \\n\n",
       "7  Run!    \\t Courez ! \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc6f57",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072b71b6",
   "metadata": {},
   "source": [
    "### 2 functions used for regex: 1 for English punctuations and 1 for French punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e597697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex reference: https://stackoverflow.com/questions/64125019/how-to-tokenize-punctuations-using-the-tokenizer-function-tensorflow\n",
    "def pad_punctuation(s): return re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)\n",
    "\n",
    "# regex French punctuations\n",
    "def french_punctuations(s):\n",
    "    s = re.sub('[\\u202f\\u2009\\xa0]', '', s)\n",
    "    s = re.sub('’', \" ' \", s)\n",
    "    s = re.sub('[—––]', ' - ', s)\n",
    "    s = re.sub('[«»]', ' \" ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bbda3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# French punctuations and unicode spaces found in French list\n",
    "# \\u202f # unicode whitespace\n",
    "# \\u2009 # unicode whitespace\n",
    "# \\xa0 # unicode whitespace\n",
    "# ’ # French apostrophe\n",
    "# — # French hyphen\n",
    "# – # French hyphen\n",
    "# – # French hyphen\n",
    "# «, » # French double quotes\n",
    "# \\u202f\\u2009\\xa0’—––«»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e542b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50              \\t Bonjour  !  \\n\n",
       "51                \\t Salut  !  \\n\n",
       "52          \\t Je comprends .  \\n\n",
       "53                   \\t Aha .  \\n\n",
       "54            \\t J ' essaye .  \\n\n",
       "55         \\t J ' ai gagné  !  \\n\n",
       "56    \\t Je l ' ai emporté  !  \\n\n",
       "57            \\t J’ai gagné .  \\n\n",
       "58               \\t Oh non  !  \\n\n",
       "59           \\t Calme - toi .  \\n\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a full list from lines.fra and separate by common punctuation\n",
    "lines.fra = [pad_punctuation(s) for s in lines.fra]\n",
    "lines.fra[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59a37b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50              \\t Bonjour  !  \\n\n",
       "51                \\t Salut  !  \\n\n",
       "52          \\t Je comprends .  \\n\n",
       "53                   \\t Aha .  \\n\n",
       "54            \\t J ' essaye .  \\n\n",
       "55         \\t J ' ai gagné  !  \\n\n",
       "56    \\t Je l ' ai emporté  !  \\n\n",
       "57          \\t J ' ai gagné .  \\n\n",
       "58               \\t Oh non  !  \\n\n",
       "59           \\t Calme - toi .  \\n\n",
       "Name: fra, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a full list from lines.fra and separate by French punctuation\n",
    "lines.fra = [french_punctuations(s) for s in lines.fra]\n",
    "lines.fra[50:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30d29b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Go . \n",
       "1    Go . \n",
       "2    Go . \n",
       "3    Go . \n",
       "4    Hi . \n",
       "Name: eng, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a full list from lines.eng and separate by punctuation\n",
    "lines.eng = [pad_punctuation(s) for s in lines.eng]\n",
    "lines.eng.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af29cbea",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb052968",
   "metadata": {},
   "source": [
    "### Tokenizing English & French data, find vocab, and length of the longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebcab624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 1], [29, 1], [29, 1]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(filters='')                       # Tokenizing by word\n",
    "eng_tokenizer.fit_on_texts(lines.eng)                       # Tokenizing 33000 Eng rows\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # words into num sequence\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b11e9612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tom', '?', '.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer.index_word[6], eng_tokenizer.index_word[5], eng_tokenizer.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6827efae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 74, 10, 2], [1, 339, 3, 2], [1, 27, 489, 10, 2]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(filters='')                         # Tokenizing by word\n",
    "fra_tokenizer.fit_on_texts(lines.fra)                         # Tokenizing 33000 Eng rows\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # words into num sequence\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe97b31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\t', '\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer.index_word[1], fra_tokenizer.index_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb35d889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 8595\n"
     ]
    }
   ],
   "source": [
    "# find vocab size\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5afa1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "# find the length of the longest sentence\n",
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b052ff65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 8595\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "# stats of English and French\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c012d40",
   "metadata": {},
   "source": [
    "### Ender and decoder preprocessing with removing tokens and adding padding seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a28ac66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw input of English\n",
    "encoder_input = input_text\n",
    "# removing eos token for Fr input\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# removing sos token for Fr target\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad0f3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 74, 10], [1, 339, 3], [1, 27, 489, 10]]\n",
      "[[74, 10, 2], [339, 3, 2], [27, 489, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbbc770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "# add padding sequence\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07449a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29  1  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f26d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for one-hot-encoding. This loads all data to a memory, use with caution as it can shutdown the kernel during overflow\n",
    "# when used, loss func to be categorical_crossentropy instead of sparse_categorical_crossentropy, since ohe already done\n",
    "\n",
    "# encoder_input = to_categorical(encoder_input)\n",
    "# decoder_input = to_categorical(decoder_input)\n",
    "# decoder_target = to_categorical(decoder_target)\n",
    "# print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "# print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "# print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a1aab2",
   "metadata": {},
   "source": [
    "### Splitting encoder and decoder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ed5a8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 20)\n",
      "enc_inp_tr (30000, 10)\n",
      "dec_inp_tr (30000, 20)\n",
      "dec_tgt_tr (30000, 20)\n",
      "enc_inp_ts (3000, 10)\n",
      "dec_inp_ts (3000, 20)\n",
      "dec_tgt_ts (3000, 20)\n"
     ]
    }
   ],
   "source": [
    "# split encoder decoder train and test\n",
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))\n",
    "print('enc_inp_tr', np.shape(encoder_input_train))\n",
    "print('dec_inp_tr', np.shape(decoder_input_train))\n",
    "print('dec_tgt_tr', np.shape(decoder_target_train))\n",
    "print('enc_inp_ts', np.shape(encoder_input_test))\n",
    "print('dec_inp_ts', np.shape(decoder_input_test))\n",
    "print('dec_tgt_ts', np.shape(decoder_target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e69aea",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c30e3c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder model\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(eng_vocab_size, 300, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_state=True, dropout=0.2)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0a8bec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decoder model\n",
    "# input tensor\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(fra_vocab_size, 300, input_length=max_fra_seq_len)(decoder_inputs)\n",
    "# LSTM with 256 units of hidden size\n",
    "decoder_lstm = LSTM(256, return_sequences = True, return_state=True, dropout=0.2)\n",
    "# decoder_outputs is all time steps hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(dec_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "accbb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax for classification\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a84750b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    1413900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2578500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 570368      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  570368      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8595)   2208915     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,342,051\n",
      "Trainable params: 7,342,051\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebdaad8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "59/59 [==============================] - 10s 91ms/step - loss: 2.3437 - val_loss: 1.8368\n",
      "Epoch 2/150\n",
      "59/59 [==============================] - 5s 81ms/step - loss: 1.4621 - val_loss: 1.5863\n",
      "Epoch 3/150\n",
      "59/59 [==============================] - 5s 82ms/step - loss: 1.2641 - val_loss: 1.4584\n",
      "Epoch 4/150\n",
      "59/59 [==============================] - 5s 83ms/step - loss: 1.1282 - val_loss: 1.3469\n",
      "Epoch 5/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 1.0318 - val_loss: 1.2771\n",
      "Epoch 6/150\n",
      "59/59 [==============================] - 5s 84ms/step - loss: 0.9643 - val_loss: 1.2187\n",
      "Epoch 7/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.9046 - val_loss: 1.1787\n",
      "Epoch 8/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.8487 - val_loss: 1.1398\n",
      "Epoch 9/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.8010 - val_loss: 1.1010\n",
      "Epoch 10/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.7603 - val_loss: 1.0699\n",
      "Epoch 11/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.7248 - val_loss: 1.0460\n",
      "Epoch 12/150\n",
      "59/59 [==============================] - 5s 87ms/step - loss: 0.6933 - val_loss: 1.0225\n",
      "Epoch 13/150\n",
      "59/59 [==============================] - 5s 88ms/step - loss: 0.6644 - val_loss: 1.0043\n",
      "Epoch 14/150\n",
      "59/59 [==============================] - 5s 87ms/step - loss: 0.6375 - val_loss: 0.9926\n",
      "Epoch 15/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.6121 - val_loss: 0.9811\n",
      "Epoch 16/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.5890 - val_loss: 0.9646\n",
      "Epoch 17/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.5659 - val_loss: 0.9539\n",
      "Epoch 18/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.5459 - val_loss: 0.9453\n",
      "Epoch 19/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.5258 - val_loss: 0.9298\n",
      "Epoch 20/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.5075 - val_loss: 0.9272\n",
      "Epoch 21/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.4896 - val_loss: 0.9180\n",
      "Epoch 22/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.4722 - val_loss: 0.9143\n",
      "Epoch 23/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.4556 - val_loss: 0.9041\n",
      "Epoch 24/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.4397 - val_loss: 0.8936\n",
      "Epoch 25/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.4243 - val_loss: 0.8953\n",
      "Epoch 26/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.4100 - val_loss: 0.8868\n",
      "Epoch 27/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3957 - val_loss: 0.8840\n",
      "Epoch 28/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3820 - val_loss: 0.8808\n",
      "Epoch 29/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3691 - val_loss: 0.8827\n",
      "Epoch 30/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3562 - val_loss: 0.8689\n",
      "Epoch 31/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3434 - val_loss: 0.8791\n",
      "Epoch 32/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3317 - val_loss: 0.8712\n",
      "Epoch 33/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3205 - val_loss: 0.8683\n",
      "Epoch 34/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.3092 - val_loss: 0.8663\n",
      "Epoch 35/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2986 - val_loss: 0.8787\n",
      "Epoch 36/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2878 - val_loss: 0.8701\n",
      "Epoch 37/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2784 - val_loss: 0.8621\n",
      "Epoch 38/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2686 - val_loss: 0.8653\n",
      "Epoch 39/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2596 - val_loss: 0.8766\n",
      "Epoch 40/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2506 - val_loss: 0.8599\n",
      "Epoch 41/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2419 - val_loss: 0.8618\n",
      "Epoch 42/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2335 - val_loss: 0.8605\n",
      "Epoch 43/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2256 - val_loss: 0.8642\n",
      "Epoch 44/150\n",
      "59/59 [==============================] - 5s 85ms/step - loss: 0.2182 - val_loss: 0.8633\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "early_stopping = EarlyStopping(patience=4) # add early stopping\n",
    "\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=512, epochs=150, callbacks=early_stopping) # batch size changed from 128 to 256 to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e90d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # keys to check parameters for plotting\n",
    "\n",
    "# acc = history_dict['accuracy']\n",
    "# val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is \"dotted blue\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# \"b\" is \"blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84d3714",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f913eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 300)         1413900   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 570368    \n",
      "=================================================================\n",
      "Total params: 1,984,268\n",
      "Trainable params: 1,984,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# encoder model: use encoder_inputs and encoder_states defined earlier \n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a401b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder model\n",
    "# previous time step's tensor with hidden state\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# previous time step's tensor with cell state\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# previous time step's tensor with hidden state and cell state in one variable\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs: use current time step as inital data/time step\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state = decoder_states_inputs)\n",
    "# curernt time step's hidden state and cell state into decoder_states\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c2af95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    2578500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  570368      embedding_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8595)   2208915     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,357,783\n",
      "Trainable params: 5,357,783\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decoder's output model\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "368b6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary for word to index and index to word for both English and French from eng_tokenizer and fra_tokenizer\n",
    "# needed to understand test results\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "449b3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define decode_sequence function for prediction/translation\n",
    "# decode_sequence()'s input is integer sequence of to be translated sentence\n",
    "# decode_sequence() has encoder model inside for encoding\n",
    "# when entered 'input_seq'(sentence int seq to be translated), encoder_model returns last hidden state\n",
    "# 'this' hidden state becomes decoder's first hidden state and decoder predicts to create translated sentence\n",
    "# during decoder pred process, model uses previous predicted words as current state's input\n",
    "# this process ends when met with eos token or becomes longer than the length of the longest French sentence, which is 20\n",
    "def decode_sequence(input_seq):\n",
    "    # receives encoder state as input\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # creates one-hot-vector for <SOS>\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = fra2idx['\\t']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # run while loop until stop_condition becomes True\n",
    "    while not stop_condition:\n",
    "        # previous states_value to be used as current initial state\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # change pred result into words\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # add pred words to predicted sentence\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # end when reached <eos> or length of the longest French sentence, which is 20\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # current state's pred result saved to be used as next state's input\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # current state saved to be used as next state\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc6e7157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Go . \n",
      "정답 문장:  Marche .  \n",
      "번역기가 번역한 문장:  en route ! \n",
      "-----------------------------------\n",
      "입력 문장: Run ! \n",
      "정답 문장:  Filez  !  \n",
      "번역기가 번역한 문장:  cours ! \n",
      "-----------------------------------\n",
      "입력 문장: Help ! \n",
      "정답 문장:  À l ' aide !  \n",
      "번역기가 번역한 문장:  aide ! \n",
      "-----------------------------------\n",
      "입력 문장: Hello ! \n",
      "정답 문장:  Bonjour  !  \n",
      "번역기가 번역한 문장:  salut ! \n",
      "-----------------------------------\n",
      "입력 문장: Relax . \n",
      "정답 문장:  Cool ,  Raoul !  \n",
      "번역기가 번역한 문장:  tranquille . \n",
      "-----------------------------------\n",
      "입력 문장: Buy it . \n",
      "정답 문장:  Achète - le  !  \n",
      "번역기가 번역한 문장:  achète - la ! \n",
      "-----------------------------------\n",
      "입력 문장: Got it ? \n",
      "정답 문장:  Pigé ?  \n",
      "번역기가 번역한 문장:  est - ce que ça a gagn\n",
      "-----------------------------------\n",
      "입력 문장: I ' m 19 . \n",
      "정답 문장:  J ' ai 19 ans .  \n",
      "번역기가 번역한 문장:  j ' ai 19 ans . \n",
      "-----------------------------------\n",
      "입력 문장: Shut up ! \n",
      "정답 문장:  Ferme - la !  \n",
      "번역기가 번역한 문장:  ferme - la ! \n",
      "-----------------------------------\n",
      "입력 문장: They won . \n",
      "정답 문장:  Ils ont gagné .  \n",
      "번역기가 번역한 문장:  ils ont gagné . \n"
     ]
    }
   ],
   "source": [
    "# use for loop to input random samples word index and predict output results\n",
    "for seq_index in [1,10,30,50,63,80,98,120,400,801]: # input words' index\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # print without sos and eos tokens\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # print without sos token"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "7386e51e",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "1회차\n",
    "- TypeError: Inputs to a layer should be tensors. Got: <keras.layers.embeddings.Embedding object at 0x7f05a2a51d30> 문제가 계속 생겼었다.\n",
    "    - 타입 에러가 뭔지는 알지만, 고치는 방법을 찾지 못했었다.\n",
    "    - https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html 여기를 가서 모델 빌딩을 따라해 보자는 마음가짐으로 한번 훑어보다가 고치는 방법을 알아내었다. Shape을 정해주고 난 후에 (encoder_inputs)을 옆에 붙여줌으로써 해결하였다.\n",
    "- TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType' 라는 문제가 decoding model을 만드는 과정에서 에러가 생겼다.\n",
    "    - 하도 에러가 계속 나서 천천히 훑어보고 모델링 셀을 다 지우고 다시 차분히 만들어 보니 잘 되었다.\n",
    "- 모델을 결국 만들고 나서 학습을 시켜보려고 하니 커널이 죽어버렸다... 다음 회차때 해결해봐야 겠다.\n",
    "\n",
    "2회차\n",
    "- 커널이 죽는 이유를 도움을 받아 알아냈다. tf module중 to_categorical이란 셀이 있는데, one-hot-encoding을 하는 기능을 가지고 있는데, 이 셀을 실행하고 나서 계속 진행하려고 하면, 메모리 초과로 모델 학습을 못하고 커널이 죽어버리는 현상이 일어났었다.\n",
    "    - 이 셀을 없애고 모델의 metrics를 categorical_crossentropy에서 sparse_categorical_crossentropy로 바꿔주니 잘 학습이 되었다.\n",
    "- 프로젝트를 진행하다가 french list에서 이상한 문장들이 있다는 것을 알아냈다.\n",
    "    - '\\u202f\\u2009\\xa0’—––«»' 이 문자들이 있었고, 구두점만 단어와 분리해놨어서 따로 추가 전처리가 필요해졌다.\n",
    "    - project 06 에서 배운 regex re.sub을 이용해 성공적으로 전처리를 하였다.\n",
    "- 학습 진행 후, 시각화를 해 보았다.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "3회차\n",
    "- test 모델을 만들어 진행해 보았다.\n",
    "    - test modeling 부분에서 계속 에러가 났다.\n",
    "        - ValueError: Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, 8595, 100)\n",
    "\n",
    "4회차\n",
    "- 마지막 셀, 번역 결과를 보는 코드에서 3회차부터 계속 에러가 났었다\n",
    "    - 모델에서 여러가지를 더하고 바꿔보고 하다가 결국 노드에 코드를 보고선 구현할 수 있었다.\n",
    "    - 번역 결과는 대부분 틀리는 것을 볼수가 있었다.\n",
    "- epoch을 많이 올려 과적합을 하니 val_loss는 내려가다 올라갔지만, 번역 문장 결과는 오히려 좋은 결과를 나타내어 혼란을 가중시켰다.\n",
    "    - 6개 이상을 맞추는 결과를 볼 수가 있어서 많이 헷갈렸다.\n",
    "    - 과적합으로 인해 test 결과가 안좋아야 하는데 번역이 더 좋아지고 더 많이 맞춘다는 것이 이해가 가지 않았다.\n",
    "\n",
    "5회차\n",
    "- 생각한 목표대로 val_loss를 줄이기 위해 여러 hyperparameter를 바꿔봤다.\n",
    "    - early stopping 추가\n",
    "    - model.fit batch_size를 128에서 256으로 그리고 512로 바꾸기\n",
    "    - encoder and decoder LSTM에 dropout 0.2 추가\n",
    "    - embedding output dim 100에서 200으로 바꾸기\n",
    "    - lstm unit을 계속 올려봤지만, 결과가 오히려 떨어지는 형태를 보여, 256으로 맞춰주었다.\n",
    "- val_loss를 0.90 언저리로 만들수 있었지만, 10개의 문장을 번역해 보았을 때, 반 정도만 말이 되는 번역으로 출력되었다.\n",
    "    - embedding output dim을 300으로 바꿔주며 val_loss를 0.85정도로 맞추니, 1번째와 7번째 문장만 틀리고 나머지 8개를 맞추는 결과를 볼수가 있었다.\n",
    "    - learning_rate를 다양하게 두고 모델을 돌려봐도 비슷한 결과를 나타내었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3cf3b",
   "metadata": {},
   "source": [
    "# 배운점\n",
    "\n",
    "- hyperparameter를 어떻게 설정하느냐에 따라 모델의 학습결과와 번역 문장의 결과가 비슷하게 또는 천차만별로 다르게 나타나는 것을 볼수가 있었다.\n",
    "    - 모델을 설계할 시, hyperparameter를 적당히 설정해야 한다는 것을 배웠다.\n",
    "    - 극단적인 설정은 오히려 결과를 나쁘게 하는 결과를 보였다.\n",
    "- 이번에 사용한 것이 저번 프로젝트랑은 다르게 functional API 였는데, 처음 사용하는 것이라 많이 버벅거렸다.\n",
    "    - Sequential API가 좀더 쉽게 설계한다는 생각이 들었다.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f271313",
   "metadata": {},
   "source": [
    "# 추가\n",
    "\n",
    "- 왜 과적합시 hyperparameter를 설정하기 전보다 더 좋은 결과를 초래했을까?\n",
    "- 모델 설계 과정?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b7ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
