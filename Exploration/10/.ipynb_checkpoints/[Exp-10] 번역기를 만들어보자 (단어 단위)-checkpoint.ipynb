{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b46f11",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2c6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow\n",
    "import os, re, string\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78bfad66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93733</th>\n",
       "      <td>Forget about that right now.</td>\n",
       "      <td>Oubliez ça tout de suite.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155679</th>\n",
       "      <td>It's one of the basic human instincts.</td>\n",
       "      <td>C'est l'un des instincts humains de base.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154080</th>\n",
       "      <td>He tapered off to one cigarette a day.</td>\n",
       "      <td>Il a diminué à une cigarette par jour.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163492</th>\n",
       "      <td>She was so tired that she couldn't walk.</td>\n",
       "      <td>Elle était tellement fatiguée qu'elle ne pouva...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175096</th>\n",
       "      <td>Have you ever been a witness in a court case?</td>\n",
       "      <td>Avez-vous jamais été témoin d'une affaire en j...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  eng  \\\n",
       "93733                    Forget about that right now.   \n",
       "155679         It's one of the basic human instincts.   \n",
       "154080         He tapered off to one cigarette a day.   \n",
       "163492       She was so tired that she couldn't walk.   \n",
       "175096  Have you ever been a witness in a court case?   \n",
       "\n",
       "                                                      fra  \\\n",
       "93733                           Oubliez ça tout de suite.   \n",
       "155679          C'est l'un des instincts humains de base.   \n",
       "154080             Il a diminué à une cigarette par jour.   \n",
       "163492  Elle était tellement fatiguée qu'elle ne pouva...   \n",
       "175096  Avez-vous jamais été témoin d'une affaire en j...   \n",
       "\n",
       "                                                       cc  \n",
       "93733   CC-BY 2.0 (France) Attribution: tatoeba.org #4...  \n",
       "155679  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "154080  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "163492  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "175096  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load file\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65518345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19124</th>\n",
       "      <td>I want a blanket.</td>\n",
       "      <td>Je veux une couverture.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25864</th>\n",
       "      <td>Take some aspirin.</td>\n",
       "      <td>Prends de l'aspirine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26725</th>\n",
       "      <td>Tom isn't a minor.</td>\n",
       "      <td>Tom n'est pas mineur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7563</th>\n",
       "      <td>I smell a rat.</td>\n",
       "      <td>Il y a anguille sous roche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30029</th>\n",
       "      <td>I made a few calls.</td>\n",
       "      <td>J'ai passé quelques coups de fil.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                fra\n",
       "19124    I want a blanket.            Je veux une couverture.\n",
       "25864   Take some aspirin.              Prends de l'aspirine.\n",
       "26725   Tom isn't a minor.              Tom n'est pas mineur.\n",
       "7563        I smell a rat.        Il y a anguille sous roche.\n",
       "30029  I made a few calls.  J'ai passé quelques coups de fil."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 5만개 샘플 사용\n",
    "lines.sample(5) # 5744, 29273"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89a7375f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29659</th>\n",
       "      <td>I don't walk a lot.</td>\n",
       "      <td>\\t Je ne marche pas beaucoup. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11946</th>\n",
       "      <td>They struggled.</td>\n",
       "      <td>\\t Elles ont eu du mal. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>Let's split.</td>\n",
       "      <td>\\t Séparons-nous ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8827</th>\n",
       "      <td>Tom is a monk.</td>\n",
       "      <td>\\t Tom est moine. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <td>Get the camera.</td>\n",
       "      <td>\\t Allez chercher l'appareil photo. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                                     fra\n",
       "29659  I don't walk a lot.        \\t Je ne marche pas beaucoup. \\n\n",
       "11946      They struggled.              \\t Elles ont eu du mal. \\n\n",
       "3659          Let's split.                   \\t Séparons-nous ! \\n\n",
       "8827        Tom is a monk.                    \\t Tom est moine. \\n\n",
       "10028      Get the camera.  \\t Allez chercher l'appareil photo. \\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '\\t'\n",
    "eos_token = '\\n'\n",
    "lines.fra = lines.fra.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2239844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Va ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Marche. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t En route ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>\\t Bouge ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t Salut. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Cours ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Run!</td>\n",
       "      <td>\\t Courez ! \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng               fra\n",
       "0   Go.        \\t Va ! \\n\n",
       "1   Go.     \\t Marche. \\n\n",
       "2   Go.  \\t En route ! \\n\n",
       "3   Go.     \\t Bouge ! \\n\n",
       "4   Hi.     \\t Salut ! \\n\n",
       "5   Hi.      \\t Salut. \\n\n",
       "6  Run!     \\t Cours ! \\n\n",
       "7  Run!    \\t Courez ! \\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e336d4",
   "metadata": {},
   "source": [
    "# Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88153b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regex reference: https://stackoverflow.com/questions/64125019/how-to-tokenize-punctuations-using-the-tokenizer-function-tensorflow\n",
    "def pad_punctuation(s): return re.sub(f\"([{string.punctuation}])\", r' \\1 ', s)\n",
    "\n",
    "# also need to regex French punctuations\n",
    "def french_punctuations(s):\n",
    "    s = re.sub('[\\u202f\\u2009\\xa0]', '', s)\n",
    "    s = re.sub('’', \" ' \", s)\n",
    "    s = re.sub('[—––]', ' - ', s)\n",
    "    s = re.sub('[«»]', ' \" ', s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eecdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# French punctuations and unicode spaces found in French list\n",
    "# \\u202f # unicode whitespace\n",
    "# \\u2009 # unicode whitespace\n",
    "# \\xa0 # unicode whitespace\n",
    "# ’ # French apostrophe\n",
    "# — # French hyphen\n",
    "# – # French hyphen\n",
    "# – # French hyphen\n",
    "# «, » # French double quotes\n",
    "# \\u202f\\u2009\\xa0’—––«»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "435af17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      \\t Va  !  \\n\n",
       "1                                   \\t Marche .  \\n\n",
       "2                                \\t En route  !  \\n\n",
       "3                                   \\t Bouge  !  \\n\n",
       "4                                   \\t Salut  !  \\n\n",
       "                            ...                    \n",
       "32995    \\t Nous avons toutes beaucoup pleuré .  \\n\n",
       "32996                \\t Nous avions tous faim .  \\n\n",
       "32997         \\t Nous avons aussi trouvé ceci .  \\n\n",
       "32998         \\t Nous sommes des gens occupés .  \\n\n",
       "32999         \\t Nous regardons la télévision .  \\n\n",
       "Name: fra, Length: 33000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.fra = [pad_punctuation(s) for s in lines.fra]\n",
    "lines.fra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845c212a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\t À l  '  aide\\u202f  !   \\n\",\n",
       " '\\t Cache  -  toi  .   \\n',\n",
       " '\\t Cachez  -  vous  .   \\n',\n",
       " '\\t Saute  .   \\n',\n",
       " '\\t Saute  .   \\n',\n",
       " '\\t Ça suffit\\u202f  !   \\n',\n",
       " '\\t Stop\\u202f  !   \\n',\n",
       " '\\t Arrête  -  toi   !   \\n',\n",
       " '\\t Attends   !   \\n',\n",
       " '\\t Attendez   !   \\n',\n",
       " '\\t Attendez  .   \\n',\n",
       " '\\t Attends   !   \\n',\n",
       " '\\t Attendez   !   \\n',\n",
       " '\\t Attends  .   \\n',\n",
       " '\\t Attendez  .   \\n',\n",
       " '\\t Commencez  .   \\n',\n",
       " '\\t Commence  .   \\n',\n",
       " '\\t Poursuis  .   \\n',\n",
       " '\\t Continuez  .   \\n',\n",
       " '\\t Poursuivez  .   \\n',\n",
       " '\\t Bonjour   !   \\n',\n",
       " '\\t Salut   !   \\n',\n",
       " '\\t Je comprends  .   \\n',\n",
       " '\\t Aha  .   \\n',\n",
       " \"\\t J  '  essaye  .   \\n\",\n",
       " \"\\t J  '  ai gagné   !   \\n\",\n",
       " \"\\t Je l  '  ai emporté   !   \\n\",\n",
       " '\\t J’ai gagné  .   \\n',\n",
       " '\\t Oh non   !   \\n',\n",
       " '\\t Calme  -  toi  .   \\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fra = [pad_punctuation(s) for s in lines.fra]\n",
    "list_fra[30:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "954b035a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\t À l  '  aide  !   \\n\",\n",
       " '\\t Cache  -  toi  .   \\n',\n",
       " '\\t Cachez  -  vous  .   \\n',\n",
       " '\\t Saute  .   \\n',\n",
       " '\\t Saute  .   \\n',\n",
       " '\\t Ça suffit  !   \\n',\n",
       " '\\t Stop  !   \\n',\n",
       " '\\t Arrête  -  toi   !   \\n',\n",
       " '\\t Attends   !   \\n',\n",
       " '\\t Attendez   !   \\n',\n",
       " '\\t Attendez  .   \\n',\n",
       " '\\t Attends   !   \\n',\n",
       " '\\t Attendez   !   \\n',\n",
       " '\\t Attends  .   \\n',\n",
       " '\\t Attendez  .   \\n',\n",
       " '\\t Commencez  .   \\n',\n",
       " '\\t Commence  .   \\n',\n",
       " '\\t Poursuis  .   \\n',\n",
       " '\\t Continuez  .   \\n',\n",
       " '\\t Poursuivez  .   \\n',\n",
       " '\\t Bonjour   !   \\n',\n",
       " '\\t Salut   !   \\n',\n",
       " '\\t Je comprends  .   \\n',\n",
       " '\\t Aha  .   \\n',\n",
       " \"\\t J  '  essaye  .   \\n\",\n",
       " \"\\t J  '  ai gagné   !   \\n\",\n",
       " \"\\t Je l  '  ai emporté   !   \\n\",\n",
       " \"\\t J ' ai gagné  .   \\n\",\n",
       " '\\t Oh non   !   \\n',\n",
       " '\\t Calme  -  toi  .   \\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fra = [french_punctuations(s) for s in list_fra]\n",
    "list_fra[30:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0902a45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go . ', 'Go . ', 'Go . ', 'Go . ', 'Hi . ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a full list from lines.eng and separate by punctuation\n",
    "list_eng = [pad_punctuation(s) for s in lines.eng]\n",
    "list_eng[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef59cb89",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6c43def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[29, 1], [29, 1], [29, 1]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(filters='')    # 문자 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(list_eng)               # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "input_text = eng_tokenizer.texts_to_sequences(list_eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "891e62ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tom', '?', '.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer.index_word[6], eng_tokenizer.index_word[5], eng_tokenizer.index_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304f6057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 74, 10, 2], [1, 339, 3, 2], [1, 27, 489, 10, 2]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer(filters='')   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(list_fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "target_text = fra_tokenizer.texts_to_sequences(list_fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3daa4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\t', '\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer.index_word[1], fra_tokenizer.index_word[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a3b46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 8595\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c9eec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11fd304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4713\n",
      "프랑스어 단어장의 크기 : 8595\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0b37d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e95aeb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 74, 10], [1, 339, 3], [1, 27, 489, 10]]\n",
      "[[74, 10, 2], [339, 3, 2], [27, 489, 10, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89ed5e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b31d4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29  1  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cdea3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input = to_categorical(encoder_input)\n",
    "# decoder_input = to_categorical(decoder_input)\n",
    "# decoder_target = to_categorical(decoder_target)\n",
    "# print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "# print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "# print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91ad7195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 20)\n",
      "enc_inp_tr (30000, 10)\n",
      "dec_inp_tr (30000, 20)\n",
      "dec_tgt_tr (30000, 20)\n",
      "enc_inp_ts (3000, 10)\n",
      "dec_inp_ts (3000, 20)\n",
      "dec_tgt_ts (3000, 20)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))\n",
    "print('enc_inp_tr', np.shape(encoder_input_train))\n",
    "print('dec_inp_tr', np.shape(decoder_input_train))\n",
    "print('dec_tgt_tr', np.shape(decoder_target_train))\n",
    "print('enc_inp_ts', np.shape(encoder_input_test))\n",
    "print('dec_inp_ts', np.shape(decoder_input_test))\n",
    "print('dec_tgt_ts', np.shape(decoder_target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86306708",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20783453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(eng_vocab_size, 100, input_length=max_eng_seq_len)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "303220e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb = Embedding(fra_vocab_size, 100, input_length=max_fra_seq_len)(decoder_inputs)\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(256, return_sequences = True, return_state=True)\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(dec_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f351566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77c60c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f29b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 100)    471300      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    859500      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 365568      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  365568      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8595)   2208915     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 4,270,851\n",
      "Trainable params: 4,270,851\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\",\n",
    "#               metrics=['accuracy']\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeac258b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 10s 25ms/step - loss: 1.6707 - val_loss: 1.4871\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 1.1203 - val_loss: 1.2918\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.9599 - val_loss: 1.1725\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.8717 - val_loss: 1.1164\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.8141 - val_loss: 1.0814\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 6s 23ms/step - loss: 0.7711 - val_loss: 1.0595\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.7341 - val_loss: 1.0274\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.7011 - val_loss: 1.0095\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.6711 - val_loss: 0.9896\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.6446 - val_loss: 0.9707\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.6192 - val_loss: 0.9620\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.5960 - val_loss: 0.9468\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.5742 - val_loss: 0.9359\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.5551 - val_loss: 0.9321\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.5372 - val_loss: 0.9308\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.5202 - val_loss: 0.9255\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.5038 - val_loss: 0.9210\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4884 - val_loss: 0.9254\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4741 - val_loss: 0.9208\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4594 - val_loss: 0.9176\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4465 - val_loss: 0.9305\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4342 - val_loss: 0.9248\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4229 - val_loss: 0.9302\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4112 - val_loss: 0.9315\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 5s 23ms/step - loss: 0.4005 - val_loss: 0.9336\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50, callbacks=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "672432bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot loss\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # keys to check parameters for plotting\n",
    "\n",
    "# acc = history_dict['accuracy']\n",
    "# val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\" is \"dotted blue\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# \"b\" is \"blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f2fe6",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d0f7c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 100)         471300    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 365568    \n",
      "=================================================================\n",
      "Total params: 836,868\n",
      "Trainable params: 836,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 우선 인코더를 정의합니다. encoder_inputs와 encoder_states는 이미 정의한 것들을 재사용합니다.\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19c0dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 디코더를 설계합니다.\n",
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11407f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, None, 256), dtype=tf.float32, name=None), name='lstm_1/PartitionedCall:1', description=\"created by layer 'lstm_1'\")\n"
     ]
    }
   ],
   "source": [
    "print(decoder_inputs)\n",
    "print(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "570cf87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    859500      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  365568      embedding_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8595)   2208915     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,433,983\n",
      "Trainable params: 3,433,983\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층을 재설계해줍니다.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00b7818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어에서 정수로, 정수에서 단어로 바꾸는 사전(dictionary)을 준비해 둡니다.\n",
    "# 테스트 결과를 해석하기 위해선 다시 사전이 필요하겠죠?\n",
    "# 우리는 이전 스텝에서 문장을 숫자 인덱스로 바꾸는 Tokenizer를 만들면서 자동으로 만들어진 사전을 이미 가지고 있습니다.\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71b6b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 예측 과정을 위한 함수 decode_sequence()를 구현합니다.\n",
    "# decode_sequence()의 입력으로 들어가는 것은 번역하고자 하는 문장의 정수 시퀀스입니다.\n",
    "# decode_sequence() 내부에는 인코더를 구현한 encoder_model이 있어서\n",
    "# 이 모델에 번역하고자 하는 문장의 정수 시퀀스인 'input_seq'를 입력하면, encoder_model은 마지막 시점의 hidden state를 리턴합니다.\n",
    "# 이 hidden state는 디코더의 첫번째 시점의 hidden state가 되고, 디코더는 이제 번역 문장을 완성하기 위한 예측 과정을 진행합니다.\n",
    "# 디코더의 예측 과정에서는 이전 시점에서 예측한 단어를 디코더의 현재 시점의 입력으로 넣어주는 작업을 진행합니다.\n",
    "# 그리고 이 작업은 종료를 의미하는 종료 토큰을 만나거나, 주어진 최대 길이를 넘을 때까지 반복합니다.\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = fra2idx['\\t']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6414e3c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Go.\n",
      "정답 문장:  Bouge  !  \n",
      "번역기가 번역한 문장:  va te faire ! \n",
      "-----------------------------------\n",
      "입력 문장: Hello!\n",
      "정답 문장:  Bonjour  !  \n",
      "번역기가 번역한 문장:  bonjour ! \n",
      "-----------------------------------\n",
      "입력 문장: Got it?\n",
      "정답 문장:  T ' as capté  ?  \n",
      "번역기가 번역한 문장:  vrai ? \n",
      "-----------------------------------\n",
      "입력 문장: Hang on.\n",
      "정답 문장:  Tiens bon  !  \n",
      "번역기가 번역한 문장:  tenez - vous bien ! \n",
      "-----------------------------------\n",
      "입력 문장: Here's $5.\n",
      "정답 문장:  Voilà cinq dollars .  \n",
      "번역기가 번역한 문장:  voici . \n"
     ]
    }
   ],
   "source": [
    "# 이렇게 구현한 함수를 임의의 인덱스의 번역하고자하는 문장 샘플을 입력하여,\n",
    "# 출력 결과를 테스트해보겠습니다.\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][1:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63a3f0",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "1회차\n",
    "- TypeError: Inputs to a layer should be tensors. Got: <keras.layers.embeddings.Embedding object at 0x7f05a2a51d30> 문제가 계속 생겼었다.\n",
    "    - 타입 에러가 뭔지는 알지만, 고치는 방법을 찾지 못했었다.\n",
    "    - https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html 여기를 가서 모델 빌딩을 따라해 보자는 마음가짐으로 한번 훑어보다가 고치는 방법을 알아내었다. Shape을 정해주고 난 후에 (encoder_inputs)을 옆에 붙여줌으로써 해결하였다.\n",
    "- TypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType' 라는 문제가 decoding model을 만드는 과정에서 에러가 생겼다.\n",
    "    - 하도 에러가 계속 나서 천천히 훑어보고 모델링 셀을 다 지우고 다시 차분히 만들어 보니 잘 되었다.\n",
    "- 모델을 결국 만들고 나서 학습을 시켜보려고 하니 커널이 죽어버렸다... 다음 회차때 해결해봐야 겠다.\n",
    "\n",
    "2회차\n",
    "- 커널이 죽는 이유를 도움을 받아 알아냈다. tf module중 to_categorical이란 셀이 있는데, one-hot-encoding을 하는 기능을 가지고 있는데, 이 셀을 실행하고 나서 계속 진행하려고 하면, 메모리 초과로 모델 학습을 못하고 커널이 죽어버리는 현상이 일어났었다.\n",
    "    - 이 셀을 없애고 모델의 metrics를 categorical_crossentropy에서 sparse_categorical_crossentropy로 바꿔주니 잘 학습이 되었다.\n",
    "- 프로젝트를 진행하다가 french list에서 이상한 문장들이 있다는 것을 알아냈다.\n",
    "    - '\\u202f\\u2009\\xa0’—––«»' 이 문자들이 있었고, 구두점만 단어와 분리해놨어서 따로 추가 전처리가 필요해졌다.\n",
    "    - project 06 에서 배운 regex re.sub을 이용해 성공적으로 전처리를 하였다.\n",
    "- 학습 진행 후, test 모델을 만들어 진행해 보았다.\n",
    "    - test modeling 부분에서 계속 에러가 났다.\n",
    "        - ValueError: Input 0 of layer lstm_1 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, 8595, 100)\n",
    "        - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daea5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
