{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f90eec94",
   "metadata": {},
   "source": [
    "# 5-4. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3281e9",
   "metadata": {},
   "source": [
    "## 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 먼저 필요한 라이브러리를 준비하세요.\n",
    "import os\n",
    "from collections import Counter\n",
    "from konlpy.tag import Komoran\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "PATH = os.getenv('HOME') + '/aiffel/socar_memo/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa5411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 준비해 두었던 뉴스 기사 데이터 KCC150_100k.txt에서 10줄만 출력해 볼게요.\n",
    "\n",
    "#print Noun in sentence\n",
    "#only 10 sentences\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "news = open(PATH+\"/KCC150_100k.txt\",'r')\n",
    "news_lines = news.read().splitlines()\n",
    "\n",
    "for idx, line in enumerate(news_lines):\n",
    "    morph_result = komoran.pos(line) #형태소 분석\n",
    "    if idx == 10:\n",
    "        break\n",
    "    print(line)\n",
    "    for word, tag in morph_result:\n",
    "        if tag.startswith('NN'): #komoran은 NNP,NNG 가 명사\n",
    "            print(word, end=' ')\n",
    "\n",
    "    print('\\n') #next line\n",
    "\n",
    "news.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad4fdf",
   "metadata": {},
   "source": [
    "## 불용어를 제거해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 준비해둔 파일 중에 korean_stopword.txt 파일에 한국어 불용어가 들어 있습니다.\n",
    "\n",
    "stopword_file = open(PATH+\"/korean_stopword.txt\",'r')\n",
    "stopword_lines = stopword_file.read().splitlines()\n",
    "\n",
    "korean_stopword = [line.split()[0] for line in stopword_lines]\n",
    "print(len(korean_stopword))\n",
    "stopword_file.close()\n",
    "print(korean_stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fc36d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한번 테스트를 해볼까요?\n",
    "\n",
    "sample_sent = '이 물건은 우리가 가지고 있는 것들 이다.'\n",
    "sample_token = komoran.morphs(sample_sent)\n",
    "\n",
    "output_token = []\n",
    "for token in sample_token:\n",
    "    if token not in korean_stopword:\n",
    "        output_token.append(token)\n",
    "\n",
    "print(output_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803e033",
   "metadata": {},
   "source": [
    "# 5-5. 단어 빈도 카운팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5505cd85",
   "metadata": {},
   "source": [
    "## 전체 단어 빈도 카운팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d98004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 기사 말뭉치 파일을 읽고, 형태소 분석기를 활용해서 형태소 분석을 진행해 보도록 하겠습니다.\n",
    "\n",
    "#파일에서 단어 기준으로 빈도를 카운팅\n",
    "#Counter 함수를 불러서 사용\n",
    "\n",
    "word_count = Counter()\n",
    "komoran = Komoran()\n",
    "\n",
    "news = open(PATH+\"/KCC150_100k.txt\",'r')\n",
    "news_lines = news.read().splitlines()\n",
    "\n",
    "for line in news_lines:\n",
    "    word_count.update(komoran.morphs(line))\n",
    "\n",
    "print(len(word_count)) #전체 단어 개수 출력\n",
    "print(word_count.most_common(10)) #빈도 상위 10개 출력\n",
    "news.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8febcf",
   "metadata": {},
   "source": [
    "## 뉴스 데이터에서 출현한 자동차 단어 빈도 카운팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cf677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에는 앞서 확인한 자동차 용어 사전을 사용해서 빈도 카운팅을 진행해 봅시다.\n",
    "# 아래 코드에서는 픽업 트럭과 같이 자동차 용어 사전에 공백이 포함되는 경우를 고려하지 않으며,\n",
    "# 오직 한 개의 어절로 이루어진 경우만 다루겠습니다.\n",
    "# 입력으로 들어가는 데이터는 위와 동일하게 뉴스 기사 말뭉치로 할게요. 조금 시간이 걸립니다.\n",
    "\n",
    "#파일에서 단어 기준으로 빈도 카운팅\n",
    "#뉴스 기사에서 자동차 단어 찾기\n",
    "\n",
    "car_count = Counter()\n",
    "komoran = Komoran()\n",
    "\n",
    "news = open(PATH+\"/KCC150_100k.txt\",'r')\n",
    "news_lines = news.read().splitlines()\n",
    "\n",
    "car_file = open(PATH+\"/carDic.txt\", 'r')\n",
    "car_words_list = car_file.read().split('\\n')\n",
    "\n",
    "for line in news_lines:\n",
    "    line = line.split() #문장 to 단어\n",
    "    car_count.update([word for word in line if word in car_words_list])\n",
    "\n",
    "print(len(car_count)) #전체 단어 개수 출력\n",
    "print(car_count.most_common(10)) #빈도 상위 10개 출력\n",
    "news.close()\n",
    "car_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c2795",
   "metadata": {},
   "source": [
    "# 5-6. Word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61004f8",
   "metadata": {},
   "source": [
    "## 전체 데이터를 Word cloud로 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7918a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#한국어 불용어 사전을 정의\n",
    "stopwords = set(korean_stopword)\n",
    "\n",
    "# CREATE WORDCLOUD\n",
    "wc = WordCloud(\n",
    "    font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
    "    background_color='white',\n",
    "    stopwords=stopwords\n",
    "    )\n",
    "wc.generate(' '.join(news_lines))\n",
    "\n",
    "# Plot wordcloud\n",
    "plt.figure(figsize=(10,8)) #plot size\n",
    "plt.imshow(wc) \n",
    "plt.axis('off') #axis delete\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d71edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 우선 형태소 분석된 결과에서 명사만 찾아 noun_sent_list를 만들어 볼게요!\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "news = open(PATH+\"/KCC150_100k.txt\",'r')\n",
    "news_lines = news.read().splitlines()\n",
    "\n",
    "noun_sent_list = []\n",
    "\n",
    "for idx, line in enumerate(news_lines):\n",
    "    morph_result = komoran.pos(line) #형태소 분석\n",
    "  \n",
    "    noun_sent = ''\n",
    "  \n",
    "    for word, tag in morph_result:\n",
    "        if tag.startswith('NN'): #komoran은 NNP,NNG 가 명사\n",
    "            noun_sent += word\n",
    "\n",
    "    noun_sent_list.append(noun_sent)\n",
    "\n",
    "print(len(noun_sent_list))\n",
    "news.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3248bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 만들어진 noun_sent_list를 시각화 해볼게요!\n",
    "\n",
    "#한국어 불용어 사전을 정의\n",
    "stopwords = set(korean_stopword)\n",
    "\n",
    "# CREATE WORDCLOUD\n",
    "wc = WordCloud(\n",
    "    font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
    "    background_color='white',\n",
    "    stopwords=stopwords\n",
    "    )\n",
    "wc.generate(' '.join(noun_sent_list))\n",
    "\n",
    "# Plot wordcloud\n",
    "plt.figure(figsize=(10,8)) #plot size\n",
    "plt.imshow(wc) \n",
    "plt.axis('off') #axis delete\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803415ee",
   "metadata": {},
   "source": [
    "## 자동차 단어만 Word cloud로 표현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd35c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 기사에서 자동차 단어를 추리는 방법으로 자동차 사전을 사용하였습니다.\n",
    "# 앞서 사용한 방법을 토대로 뉴스 기사에서 자동차 관련 단어만 추려보고, 이를 Word cloud로 표현해 보도록 할게요.\n",
    "# 여기서도 앞에서 언급한 것처럼 한 개의 어절로 이루어진 자동차 단어만 다룹니다.\n",
    "# 우선 자동차 관련 단어만 골라 car_sent_list에 담습니다.\n",
    "\n",
    "komoran = Komoran()\n",
    "\n",
    "news = open(PATH+\"/KCC150_100k.txt\",'r')\n",
    "news_lines = news.read().splitlines()\n",
    "\n",
    "car_file = open(PATH+\"/carDic.txt\", 'r')\n",
    "car_words_list = car_file.read().split('\\n')\n",
    "\n",
    "car_sent_list = []\n",
    "\n",
    "for line in news_lines:\n",
    "    line = line.split() #문장 to 단어\n",
    "    car_sent_list.append(' '.join([word for word in line if word in car_words_list]))\n",
    "\n",
    "print(len(car_sent_list))\n",
    "news.close()\n",
    "car_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01905e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 시각화 해봅시다!\n",
    "\n",
    "#한국어 불용어 사전을 정의\n",
    "stopwords = set(korean_stopword)\n",
    "\n",
    "# CREATE WORDCLOUD\n",
    "wc = WordCloud(\n",
    "    font_path='/usr/share/fonts/truetype/nanum/NanumGothic.ttf',\n",
    "    background_color='white',\n",
    "    stopwords=stopwords\n",
    "    )\n",
    "wc.generate(' '.join(car_sent_list))\n",
    "\n",
    "# Plot wordcloud\n",
    "plt.figure(figsize=(10,8)) #plot size\n",
    "plt.imshow(wc) \n",
    "plt.axis('off') #axis delete\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1a3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
